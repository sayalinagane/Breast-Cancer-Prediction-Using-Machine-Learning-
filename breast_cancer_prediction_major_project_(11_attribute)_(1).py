# -*- coding: utf-8 -*-
"""Breast_Cancer_Prediction_Major_Project_(11_attribute)_(1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pJyQ6hjPffreIAua9LDcrKRyxaLpjZ_6
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler

"""# New Section"""

# load data
df = pd.read_csv('Wisconsin Dataset.csv')

df.head()

df.tail()

df.shape

df.describe()

#column Class
df.Class.unique()

#Bar Chart
sns.countplot(df['Class'], palette='husl')

#clean and prepare the data
#Sample code number column names
df.drop('Sample code number',axis=1,inplace=True)

df['Class'].value_counts()

df.isnull().sum()

#Correlation explains how one or more variables are related to each other.
#These variables can be input data features which have been used to forecast our target variable.
df.corr()

classMapping = { 2:0, 4:1 }
df['Class']=df['Class'].map(classMapping)

x_var=df.loc[:,df.columns!='Class']
y_var=df.Class

plt.hist(df['Class'], color='g')
plt.title('Plot_Diagnosis (M=4 , B=2)')
plt.show()

plt.figure(figsize=(5,5))
sns.heatmap(df.corr(), annot=True)
#as in below heatmap we can say that there is high coorelation between Uniformity of Cell Size and Uniformity of Cell Shape

# Building Model
X=df.drop(['Class'],axis=1)
y = df['Class']

#Label Encoding
#Encoding categorical data values
#into machine readable form
from sklearn.preprocessing import LabelEncoder
labelencoder_y = LabelEncoder()
y= labelencoder_y.fit_transform(y)

from sklearn.model_selection import train_test_split

# Here we are using the split ratio of 80:20. The 20% testing data set is represented by the 0.2 at the end.
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=40)

# Feature Scaling
from sklearn.preprocessing import StandardScaler
ss=StandardScaler()

X_train=ss.fit_transform(X_train)
X_test=ss.fit_transform(X_test)

#Logistic Regression
from sklearn.linear_model import LogisticRegression
lr=LogisticRegression()

model1=lr.fit(X_train,y_train)
prediction1=model1.predict(X_test)

from sklearn.metrics import confusion_matrix

cm=confusion_matrix(y_test,prediction1)
cm

sns.heatmap(cm,annot=True)
plt.savefig('h.png')

TN=cm[0][0]
TP=cm[1][1]
FN=cm[1][0]
FP=cm[0][1]
print('Testing Accuracy:',(TP+TN)/(TP+TN+FN+FP))

from sklearn.metrics import accuracy_score

accuracy_score(y_test,prediction1)

from sklearn.metrics import classification_report
print(classification_report(y_test, prediction1))

#Support Vector Machine
from sklearn.svm import SVC
models=[]
models.append(('SVM', SVC()))

SVM = SVC()
SVM.fit(X_train, y_train)
predictions= SVM.predict(X_test)
print(accuracy_score(y_test, predictions))
print(classification_report(y_test, predictions))
print(confusion_matrix(y_test, predictions))

# Get input from user
input_data = []
feature_names = ['Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses']
for feature in feature_names:
    val = input(f"Enter {feature}: ")
    input_data.append(float(val))

# Check if any of the input values is greater than a certain value
threshold = 6
if any(val > threshold for val in input_data):
    prediction = 1  # Set prediction to malignant
else:
    # Scale the input data
    input_data = ss.transform([input_data])

    # Make a prediction on the user input
    prediction = model1.predict(input_data)[0]

# Print the result
if prediction == 0:
    print("The diagnosis is benign.")
else:
    print("The diagnosis is malignant.")